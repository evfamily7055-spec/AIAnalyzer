import streamlit as st
import pandas as pd
import io
import json
import traceback
import datetime
import streamlit.runtime

# --- ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (Import Libraries) ---

# Gemini AI
try:
    import google.generativai as genai
    from google.api_core import exceptions as google_exceptions
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

# ã‚°ãƒ©ãƒ•æç”» (Visualization)
try:
    import plotly.express as px
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

# æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆãƒã‚¤ãƒ‹ãƒ³ã‚° (NLP)
try:
    from janome.tokenizer import Tokenizer
    from janome.tokenfilter import POSKeepFilter, TokenCountFilter
    from janome.analyzer import Analyzer
    JANOME_AVAILABLE = True
except ImportError:
    JANOME_AVAILABLE = False

# çµ±è¨ˆçš„ä»®èª¬æ¤œå®š (Statistics)
try:
    from scipy import stats
    import statsmodels.api as sm
    STATS_LIBS_AVAILABLE = True
except ImportError:
    STATS_LIBS_AVAILABLE = False

# --- å®šæ•° (Constants) ---
MAX_UNIQUE_VALUES_FOR_SCHEMA = 20

# --- ãƒšãƒ¼ã‚¸è¨­å®š (Page Config) ---
st.set_page_config(layout="wide")
st.title("AIãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆ (å±¥æ­´æ©Ÿèƒ½ä»˜ã) ğŸš€")
st.info("é›†è¨ˆãƒ»å¯è¦–åŒ–ãƒ»ãƒ†ã‚­ã‚¹ãƒˆãƒã‚¤ãƒ‹ãƒ³ã‚°ãƒ»çµ±è¨ˆæ¤œå®šãƒ»è«–æ–‡ç”¨è§£èª¬ã¾ã§ã€AIãŒãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§å®Ÿè¡Œã€‚åˆ†æå±¥æ­´ã‚‚ä¿å­˜ã—ã¾ã™ã€‚")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ– (Initialize Session State) ---
def init_session_state():
    defaults = {
        'df': None,
        'schema_dict': None,
        'current_prompt': "",
        'current_code': "",
        'current_output': None,
        'current_explanation': "",
        'current_interpretation': "",
        'last_uploaded_filename': None,
        'analysis_history': []  # (NEW) å±¥æ­´ä¿å­˜ç”¨ãƒªã‚¹ãƒˆ
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

init_session_state()

# --- Gemini API å‘¼ã³å‡ºã—é–¢æ•° ---
@st.cache_data(ttl=600)
def generate_code_and_explanation(schema_json: str, user_prompt: str, api_key: str):
    """
    æ‹¡å¼µã‚¹ã‚­ãƒ¼ãƒã¨æŒ‡ç¤ºã‚’Geminiã«é€ä¿¡ã—ã€
    ã€Œã‚³ãƒ¼ãƒ‰ã€ã€Œåˆ†æèª¬æ˜ã€ã€Œçµ±è¨ˆçš„è§£é‡ˆã€ã‚’å«ã‚€JSONã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    if not GEMINI_AVAILABLE:
        st.error("google.generativeai ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`pip install google-generativeai` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return None

    try:
        genai.configure(api_key=api_key)
    except Exception as e:
        st.error(f"APIã‚­ãƒ¼ã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

    # (v3 Stable) å®‰å®šæ€§ã®ãŸã‚ã€ã‚¹ã‚¿ã‚¤ãƒ«(template)ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’é™¤å¤–ã—ã€çµ±è¨ˆæ¤œå®šã®æŒ‡ç¤ºã‚’å¼·åŒ–
    system_prompt = (
        "ã‚ãªãŸã¯ã€Pandas, Plotly (px), Janome (NLP), Scipy (stats), Statsmodels (sm) ã‚’å°‚é–€ã¨ã™ã‚‹ä¸–ç•Œã‚¯ãƒ©ã‚¹ã®Pythonãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚"
        "ã‚ãªãŸã®ä»•äº‹ã¯ã€æ¸¡ã•ã‚ŒãŸã€Œãƒ‡ãƒ¼ã‚¿ã‚¹ã‚­ãƒ¼ãƒã€ã¨ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ›–æ˜§ãªæŒ‡ç¤ºã€ã‹ã‚‰ã€ã€Œå®Ÿè¡Œã‚³ãƒ¼ãƒ‰ã€ã€Œåˆ†æå†…å®¹ã®æ—¥æœ¬èªèª¬æ˜ã€ã€Œçµ±è¨ˆçš„è§£é‡ˆã€ã®3ã¤ã‚’ *JSONå½¢å¼* ã§ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã™ã€‚"
        
        "## ãƒ«ãƒ¼ãƒ«:"
        "1. å‡ºåŠ›ã¯ *å¿…ãš* ä»¥ä¸‹ã®JSONå½¢å¼ã® *æ–‡å­—åˆ—ã®ã¿* ã¨ã—ã¦ãã ã•ã„ã€‚èª¬æ˜ã‚„ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ï¼ˆ```json ãªã©ï¼‰ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚"
        "   {\n"
        "     \"code_to_execute\": \"... (ã“ã“ã«Pythonã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’è¨˜è¿°) ...\",\n"
        "     \"analysis_explanation\": \"... (ã“ã“ã«åˆ†æå†…å®¹ã®æ—¥æœ¬èªèª¬æ˜ã‚’è¨˜è¿°) ...\",\n"
        "     \"statistical_interpretation\": \"... (ã“ã“ã«çµ±è¨ˆæ¤œå®šã®çµæœã®è§£é‡ˆã‚’è¨˜è¿°) ...\"\n"
        "   }\n"
        
        "2. `code_to_execute` ã®ãƒ«ãƒ¼ãƒ«:"
        "   - å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¯ *å¸¸ã«* `df` ã¨ã„ã†åå‰ã§ã™ã€‚"
        "   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã‹ã‚‰ã€é›†è¨ˆ(Pandas), ã‚°ãƒ©ãƒ•(Plotly as px), NLP(Janome), çµ±è¨ˆæ¤œå®š(scipy.stats as stats, statsmodels.api as sm) ã®ã©ã‚ŒãŒæœ€é©ã‹ *æ¨è«–* ã—ã¦ãã ã•ã„ã€‚"
        "   - (STABILITY) ã‚°ãƒ©ãƒ•æç”»æ™‚ (px.pie, px.bar ãªã©) ã€`template` ã®ã‚ˆã†ãªå¤–è¦³ã«é–¢ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¯ *çµ¶å¯¾* ã«æŒ‡å®šã—ãªã„ã§ãã ã•ã„ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚"
        "   - ã‚³ãƒ¼ãƒ‰ã® *æœ€çµ‚è¡Œ* ã¯ã€çµæœï¼ˆDataFrame, Series, Plotly Figure, ã¾ãŸã¯æ¤œå®šçµæœã®æ–‡å­—åˆ—/DataFrameï¼‰ã‚’ `output` ã¨ã„ã†å˜ä¸€ã®å¤‰æ•°ã« *å¿…ãš* ä»£å…¥ã—ã¦ãã ã•ã„ã€‚"
        "   - `print()` ã‚„ `fig.show()` æ–‡ã¯ *çµ¶å¯¾ã«* ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚"
        
        "3. `analysis_explanation` ã®ãƒ«ãƒ¼ãƒ«:"
        "   - `code_to_execute` ã§å®Ÿè¡Œã™ã‚‹åˆ†æãŒ *ä½•ã‚’ã—ã¦ã„ã‚‹ã‹* ã‚’ã€å­¦è¡“è«–æ–‡ã®ã€Œæ–¹æ³•ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ä½¿ãˆã‚‹ã€å®¢è¦³çš„ã‹ã¤ç°¡æ½”ãªæ—¥æœ¬èªã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
        "   - ï¼ˆä¾‹: ã€Œ'Gender' åˆ—ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã‚­ãƒ¼ã¨ã—ã€'Age' åˆ—ã®å¹³å‡å€¤ã‚’ç®—å‡ºã—ãŸã€‚ã€ï¼‰"

        "4. `statistical_interpretation` ã®ãƒ«ãƒ¼ãƒ«:"
        "   - *çµ±è¨ˆæ¤œå®šã‚’å®Ÿè¡Œã—ãŸå ´åˆã®ã¿*ã€ãã®çµæœï¼ˆpå€¤ã€çµ±è¨ˆé‡ãªã©ï¼‰ã‚’è«–æ–‡ã®ã€Œçµæœã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ä½¿ãˆã‚‹ã‚ˆã†ã«æ—¥æœ¬èªã§è§£é‡ˆã—ã¦ãã ã•ã„ã€‚"
        "   - ï¼ˆä¾‹: ã€Œtæ¤œå®šã®çµæœã€på€¤ã¯0.03ã§ã‚ã‚Šã€5%æ°´æº–ã§æœ‰æ„ãªå·®ãŒèªã‚ã‚‰ã‚ŒãŸã€‚ã€ï¼‰"
        "   - *çµ±è¨ˆæ¤œå®šã§ãªã„å ´åˆï¼ˆå˜ç´”é›†è¨ˆã‚„ã‚°ãƒ©ãƒ•æç”»ï¼‰ã¯ã€ã“ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯ç©ºæ–‡å­—åˆ— \"\" ã¨ã—ã¦ãã ã•ã„ã€‚*"

        "5. çµ±è¨ˆæ¤œå®šã®æŒ‡ç¤ºï¼ˆä¾‹: ã€Œå·®ãŒã‚ã‚‹ã‹æ¤œå®šã€ã€Œé–¢é€£ã‚’åˆ†æã€ã€Œç›¸é–¢ã‚’èª¿ã¹ã¦ã€ï¼‰ã®å ´åˆ:"
        "   - ã‚¹ã‚­ãƒ¼ãƒï¼ˆãƒ‡ãƒ¼ã‚¿å‹ã€ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ã®æ•°ï¼‰ã«åŸºã¥ãã€æœ€é©ãªæ¤œå®šæ‰‹æ³•ã‚’ *è‡ªå‹•ã§é¸æŠ* ã—ã¦ãã ã•ã„ã€‚"
        "   - (A) 2ã¤ã®æ•°å€¤å¤‰æ•°ã®é–¢ä¿‚æ€§ -> ç›¸é–¢åˆ†æ (`stats.pearsonr`)ã€‚çµæœã¯ `r, p = stats.pearsonr(...)` ã¨ã—ã€`output = f'ç›¸é–¢ä¿‚æ•°(r): {r:.4f}, på€¤: {p:.4g}'` ã®ã‚ˆã†ã«æ–‡å­—åˆ—ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        "   - (B) ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°(2ç¾¤) vs æ•°å€¤å¤‰æ•° -> ç‹¬ç«‹2ç¾¤ã®tæ¤œå®š (`stats.ttest_ind`)ã€‚`group1 = df[df['Group'] == 'A']['Value']`, `group2 = ...` ã®ã‚ˆã†ã«ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã€`stats.ttest_ind(group1, group2, nan_policy='omit')` ã‚’å®Ÿè¡Œã€‚çµæœã¯ `stat, p = ...` ã¨ã—ã€`output = f'tå€¤: {stat:.4f}, på€¤: {p:.4g}'` ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        "   - (C) 2ã¤ã®ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®é–¢ä¿‚æ€§ -> ã‚«ã‚¤äºŒä¹—æ¤œå®š (`stats.chi2_contingency`)ã€‚`crosstab = pd.crosstab(df['Var1'], df['Var2'])` ã§ã‚¯ãƒ­ã‚¹è¡¨ã‚’ä½œæˆã—ã€`chi2, p, dof, ex = stats.chi2_contingency(crosstab)` ã‚’å®Ÿè¡Œã€‚`output = f'ã‚«ã‚¤äºŒä¹—å€¤: {chi2:.4f}, på€¤: {p:.4g}, è‡ªç”±åº¦: {dof}'` ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        "   - (D) 1ã¤ã®æ•°å€¤å¤‰æ•° (X) ã‹ã‚‰ 1ã¤ã®æ•°å€¤å¤‰æ•° (Y) ã‚’äºˆæ¸¬ -> å˜å›å¸°åˆ†æ (`sm.OLS`)ã€‚`X = sm.add_constant(df['X'].dropna())`, `Y = df['Y'].dropna()`, `X, Y = X.align(Y, join='inner')` ã§æ¬ æå€¤ã‚’é™¤å»ãƒ»æ•´åˆ—ã€‚`model = sm.OLS(Y, X).fit()`, `output = model.summary().as_text()` ã§ *ã‚µãƒãƒªãƒ¼å…¨ä½“ã‚’æ–‡å­—åˆ—ã¨ã—ã¦* è¿”ã—ã¦ãã ã•ã„ã€‚"
        
        "6. (NLP) æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆãƒã‚¤ãƒ‹ãƒ³ã‚°ã®æŒ‡ç¤ºï¼ˆä¾‹: ã€Œè‡ªç”±å›ç­”ã‚’åˆ†æã€ã€Œå˜èªé »åº¦ã€ï¼‰ã®å ´åˆ:"
        "   - `janome.tokenizer.Tokenizer` ã‚’ä½¿ç”¨ã€‚åˆ†æå¯¾è±¡ã¯ *åè©*, *å‹•è©*, *å½¢å®¹è©* ã® *åŸå½¢* ã¨ã—ã¦ãã ã•ã„ã€‚"
        "   - `stop_words` (ä¾‹: 'ã™ã‚‹', 'ã‚ã‚‹', 'ãªã„', 'ã“ã¨', 'ã‚‚ã®') ã‚’å®šç¾©ã—ã€é™¤å¤–ã€‚"
        "   - å˜èªé »åº¦ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã€ä¸Šä½50ä»¶ã‚’ `pd.DataFrame(..., columns=['word', 'count'])` ã«æ ¼ç´ã€‚"
        "   - æœ€å¾Œã« `px.treemap` ã‚’ä½¿ç”¨ã—ã€`path=[px.Constant('all'), 'word']`, `values='count'` ã§çµæœã‚’å¯è¦–åŒ–ã—ã€ãã‚Œã‚’ `output` ã«ä»£å…¥ã€‚"
    )

    model = genai.GenerativeModel(
        model_name="gemini-2.5-flash-preview-09-2025",
        system_instruction=system_prompt,
        generation_config={"response_mime_type": "application/json"}
    )
    
    full_prompt = (
        f"## ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚­ãƒ¼ãƒ (JSONå½¢å¼):\n{schema_json}\n\n"
        f"## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤º:\n{user_prompt}"
    )

    try:
        response = model.generate_content(full_prompt)
        response_json = response.text.strip()
        response_data = json.loads(response_json)
        return response_data
    except json.JSONDecodeError as e:
        st.error(f"AIãŒJSONå½¢å¼ã§ãªã„å¿œç­”ã‚’è¿”ã—ã¾ã—ãŸã€‚AIã®å¿œç­”: {response.text}\nã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except google_exceptions.InvalidArgument as e:
        st.error(f"APIã‚­ãƒ¼ãŒç„¡åŠ¹ã€ã¾ãŸã¯è¨­å®šãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“: {e}")
        return None
    except Exception as e:
        st.error(f"Gemini API å‘¼ã³å‡ºã—ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\n{traceback.format_exc()}")
        return None

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ (Sidebar) ---
with st.sidebar:
    st.header("è¨­å®š")
    api_key = st.text_input("Gemini API Key", type="password", help="Gemini APIã‚­ãƒ¼ã‚’ã“ã“ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    st.markdown("---")
    st.info("ã“ã®ã‚¢ãƒ—ãƒªã¯å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’AIã«é€ä¿¡ã—ã¾ã›ã‚“ã€‚AIã«ã¯åˆ—åã¨ã‚«ãƒ†ã‚´ãƒªã®ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ï¼ˆ20ç¨®é¡ä»¥ä¸‹ï¼‰ã®ã¿ãŒé€ä¿¡ã•ã‚Œã¾ã™ã€‚")
    
    # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒã‚§ãƒƒã‚¯
    lib_errors = []
    if not GEMINI_AVAILABLE: lib_errors.append("google.generativeai")
    if not PLOTLY_AVAILABLE: lib_errors.append("plotly")
    if not JANOME_AVAILABLE: lib_errors.append("janome (NLPæ©Ÿèƒ½ãŒç„¡åŠ¹)")
    if not STATS_LIBS_AVAILABLE: lib_errors.append("scipy, statsmodels (çµ±è¨ˆæ¤œå®šãŒç„¡åŠ¹)")
    
    if lib_errors:
        st.error(f"ä»¥ä¸‹ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {', '.join(lib_errors)}\n`pip install -r requirements.txt` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

# --- 1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ (File Uploader) ---
uploaded_file = st.file_uploader("Excelãƒ•ã‚¡ã‚¤ãƒ« (.xlsx) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["xlsx"])

if uploaded_file is not None:
    # (BUG FIX) ãƒ•ã‚¡ã‚¤ãƒ«åãŒå‰å›ã¨ç•°ãªã‚‹ã€Œæ–°ã—ã„ã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®å ´åˆã®ã¿DFã‚’èª­ã¿è¾¼ã¿ã€çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
    if uploaded_file.name != st.session_state.last_uploaded_filename:
        try:
            st.info(f"'{uploaded_file.name}' ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
            bytes_data = uploaded_file.getvalue()
            df = pd.read_excel(io.BytesIO(bytes_data))
            
            st.session_state.df = df 
            st.session_state.last_uploaded_filename = uploaded_file.name
            
            # æ‹¡å¼µã‚¹ã‚­ãƒ¼ãƒã®ç”Ÿæˆ
            schema = {}
            for col in df.columns:
                dtype = str(df[col].dtype)
                schema[col] = {"dtype": dtype}
                
                # (TypeError FIX) Numpyå‹ã‚’Pythonæ¨™æº–å‹ã«ã‚­ãƒ£ã‚¹ãƒˆ
                if pd.api.types.is_numeric_dtype(df[col]):
                    try:
                        schema[col]["mean"] = float(df[col].mean())
                        schema[col]["min"] = float(df[col].min())
                        schema[col]["max"] = float(df[col].max())
                    except (TypeError, ValueError):
                        pass # å¤‰æ›ä¸èƒ½ãªå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                elif dtype == 'object' and df[col].nunique() <= MAX_UNIQUE_VALUES_FOR_SCHEMA:
                    try:
                        unique_vals = df[col].dropna().unique().tolist()
                        schema[col]["unique_values"] = unique_vals
                    except Exception:
                        pass # æ¯”è¼ƒä¸èƒ½ãªå‹ï¼ˆãƒªã‚¹ãƒˆãªã©ï¼‰ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                     
            st.session_state.schema_dict = schema
            st.success(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ (è¡Œ: {len(df)}, åˆ—: {len(df.columns)})")
            
            # (FIX) æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚ŒãŸã‚‰ã€ç¾åœ¨ã®è¡¨ç¤ºã¨å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ
            init_session_state()
            st.session_state.df = df # dfã¨schemaã¨ãƒ•ã‚¡ã‚¤ãƒ«åã ã‘ã¯ä¿æŒã™ã‚‹
            st.session_state.schema_dict = schema
            st.session_state.last_uploaded_filename = uploaded_file.name
            
        except Exception as e:
            st.error(f"Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\n{traceback.format_exc()}")
            init_session_state() # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚å®Œå…¨ã«ãƒªã‚»ãƒƒãƒˆ

# --- (NEW) åˆ†æçµæœã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•° ---
def display_analysis_results(prompt, code, output, explanation, interpretation):
    """
    å·¦ã‚«ãƒ©ãƒ ï¼ˆä½œæ¥­é ˜åŸŸï¼‰ã«ç¾åœ¨ã®åˆ†æçµæœã‚’è¡¨ç¤ºã™ã‚‹
    """
    st.header("Step 2: å®Ÿè¡Œçµæœã¨åˆ†æã®è§£èª¬")

    if explanation:
        st.subheader("åˆ†æå†…å®¹ã®è§£èª¬ï¼ˆè«–æ–‡ã®ã€Œæ–¹æ³•ã€ç”¨ï¼‰")
        st.success(f"ğŸ“„ {explanation}")
    
    if interpretation:
        st.subheader("çµ±è¨ˆçš„è§£é‡ˆï¼ˆè«–æ–‡ã®ã€Œçµæœã€ç”¨ï¼‰")
        st.info(f"ğŸ“ˆ {interpretation}")
    
    if output is not None:
        
        # 1. çµæœãŒãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ« (DataFrame or Series) ã®å ´åˆ
        if isinstance(output, (pd.DataFrame, pd.Series)):
            st.subheader("é›†è¨ˆãƒ»åˆ†æçµæœ (ãƒ†ãƒ¼ãƒ–ãƒ«)")
            st.dataframe(output, use_container_width=True)
            
            @st.cache_data
            def convert_df_to_csv(df_to_convert):
                if not isinstance(df_to_convert, pd.DataFrame):
                    df_to_convert = df_to_convert.to_frame()
                return df_to_convert.to_csv(index=True).encode('utf-8-sig')
            
            try:
                csv_data = convert_df_to_csv(output)
                st.download_button(label="çµæœã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv_data, file_name="analysis_result.csv", mime="text/csv")
            except Exception as e:
                st.error(f"CSVå¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

        # 2. çµæœãŒã‚°ãƒ©ãƒ• (Plotly Figure) ã®å ´åˆ
        elif PLOTLY_AVAILABLE and isinstance(output, go.Figure):
            st.subheader("ç”Ÿæˆã•ã‚ŒãŸã‚°ãƒ©ãƒ•")
            st.plotly_chart(output, use_container_width=True)
            
            # (FIX) Streamlit Cloud (is_streamlit_cloud) ã‹ã©ã†ã‹ã‚’åˆ¤å®š
            is_cloud = False
            if streamlit.runtime.exists():
                from streamlit.runtime.scriptrunner import get_script_run_ctx
                try:
                    # Streamlit Cloud (Share) ã¯ is_owner ãŒ False ã«ãªã‚‹
                    is_cloud = not get_script_run_ctx().client.is_owner
                except Exception:
                    # ãƒ­ãƒ¼ã‚«ãƒ«ã‚„åˆ¤å®šä¸èƒ½ãªå ´åˆã¯ Cloud ã§ã¯ãªã„ã¨ã¿ãªã™
                    pass
            
            if is_cloud:
                st.warning("ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã™ã‚‹ã«ã¯ã€ã‚°ãƒ©ãƒ•å³ä¸Šã®ã€Œã‚«ãƒ¡ãƒ©ğŸ“·ã€ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã€ã€ŒDownload plot as a pngã€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
            else:
                # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®å ´åˆã®ã¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
                try:
                    img_bytes = output.to_image(format="png", scale=2)
                    st.download_button(
                        label="ã‚°ãƒ©ãƒ•ã‚’ç”»åƒ(PNG)ã§ä¿å­˜ (ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ)",
                        data=img_bytes,
                        file_name="chart.png",
                        mime="image/png"
                    )
                except Exception as e:
                    st.warning(f"ç”»åƒã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ChromeãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„: {e}")

        # 3. çµæœãŒçµ±è¨ˆã‚µãƒãƒªãƒ¼ (æ–‡å­—åˆ—) ã®å ´åˆ
        elif isinstance(output, str):
            st.subheader("åˆ†æãƒ»æ¤œå®šçµæœ (ã‚µãƒãƒªãƒ¼)")
            st.text(output) 
        
        # 4. ãã®ä»–ã®çµæœ
        else:
            st.subheader("å®Ÿè¡Œçµæœ (ãã®ä»–)")
            st.write(output)
    else:
        st.info("Step 1ã§åˆ†ææŒ‡ç¤ºã‚’å‡ºã—ã€ã€Œåˆ†æã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")

    # å®Ÿè¡Œã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã¯ã€çµæœã®ä¸‹ã«æŠ˜ã‚ŠãŸãŸã‚“ã§è¡¨ç¤º
    if code:
        with st.expander(f"æŒ‡ç¤º:ã€Œ{prompt}ã€ã®ãŸã‚ã«å®Ÿè¡Œã•ã‚ŒãŸPythonã‚³ãƒ¼ãƒ‰"):
            st.code(code, language="python")

# --- 2. ãƒ¡ã‚¤ãƒ³ã®ä½œæ¥­é ˜åŸŸ (å·¦å³åˆ†å‰²) ---
if st.session_state.df is not None:
    st.markdown("---")
    
    col1, col2 = st.columns([2, 1]) # å·¦ã‚«ãƒ©ãƒ ã‚’åºƒãã™ã‚‹ (2:1)

    # --- å·¦ã‚«ãƒ©ãƒ  (col1): AIã¸ã®æŒ‡ç¤ºã¨å®Ÿè¡Œçµæœï¼ˆä½œæ¥­é ˜åŸŸï¼‰ ---
    with col1:
        st.header("Step 1: AIã¸ã®åˆ†ææŒ‡ç¤º")
        st.write("å³å´ã§ãƒ‡ãƒ¼ã‚¿ï¼ˆåˆ—åï¼‰ã‚’ç¢ºèªã—ãªãŒã‚‰ã€å®Ÿè¡Œã—ãŸã„å†…å®¹ã‚’æ—¥æœ¬èªã§æŒ‡ç¤ºã—ã¦ãã ã•ã„ã€‚")
        
        user_prompt = st.text_area(
            "æŒ‡ç¤ºå…¥åŠ›æ¬„:",
            placeholder=(
                "ï¼ˆé›†è¨ˆä¾‹ï¼‰: ã€Œç”·å¥³åˆ¥ã®å¹´é½¢ã®å¹³å‡å€¤ã€\n"
                "ï¼ˆå¯è¦–åŒ–ä¾‹ï¼‰: ã€Œ'å¹´é½¢' ã¨ 'çµ¦ä¸' ã®æ•£å¸ƒå›³ã‚’è¡¨ç¤ºã€\n"
                "ï¼ˆNLPä¾‹ï¼‰: ã€Œ'è‡ªç”±å›ç­”' åˆ—ã®å˜èªé »åº¦ã‚’å¯è¦–åŒ–ã€\n"
                "ï¼ˆæ¤œå®šä¾‹ï¼‰: ã€Œ'ä»‹å…¥ç¾¤' ã¨ 'å¯¾ç…§ç¾¤' ã§ 'ã‚¹ã‚³ã‚¢' ã«å·®ãŒã‚ã‚‹ã‹æ¤œå®šã€\n"
                "ï¼ˆæ¤œå®šä¾‹ï¼‰: ã€Œ'å¹´é½¢' ã¨ 'çµ¦ä¸' ã®ç›¸é–¢ã‚’åˆ†æã—ã¦ã€"
            ),
            height=150,
            key="current_prompt" # (NEW) å±¥æ­´å‘¼ã³å‡ºã—ã®ãŸã‚ã«ã‚­ãƒ¼ã‚’è¨­å®š
        )

        if st.button("ğŸ¤– åˆ†æã‚’å®Ÿè¡Œ", type="primary"):
            if not api_key:
                st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            elif not user_prompt:
                st.warning("æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            # (çœç•¥) ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒã‚§ãƒƒã‚¯ ...
            
            else:
                with st.spinner("AIãŒã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã€ã‚µãƒ¼ãƒãƒ¼ä¸Šã§å®Ÿè¡Œä¸­ã§ã™..."):
                    # 1. AIã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
                    schema_json = json.dumps(st.session_state.schema_dict, indent=2, ensure_ascii=False)
                    response_data = generate_code_and_explanation(schema_json, user_prompt, api_key)
                    
                    if not response_data or "code_to_execute" not in response_data:
                        st.error("AIã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        st.stop()

                    code = response_data.get("code_to_execute", "")
                    explanation = response_data.get("analysis_explanation", "(èª¬æ˜ãªã—)")
                    interpretation = response_data.get("statistical_interpretation", "")
                    
                    if not code:
                        st.error("AIã¯å¿œç­”ã—ã¾ã—ãŸãŒã€å®Ÿè¡Œå¯èƒ½ãªã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚")
                        st.stop()

                    # 2. ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ
                    output = None
                    try:
                        global_vars = {"pd": pd}
                        if PLOTLY_AVAILABLE:
                            global_vars["px"] = px
                            global_vars["go"] = go
                        if JANOME_AVAILABLE:
                            global_vars["Tokenizer"] = Tokenizer
                            global_vars["Analyzer"] = Analyzer
                            global_vars["POSKeepFilter"] = POSKeepFilter
                            global_vars["TokenCountFilter"] = TokenCountFilter
                        if STATS_LIBS_AVAILABLE:
                            global_vars["stats"] = stats
                            global_vars["sm"] = sm
                            
                        local_vars = {"df": st.session_state.df.copy()} 
                        
                        exec(code, global_vars, local_vars)
                        
                        output = local_vars.get("output", None)
                        
                        if output is not None:
                            # (NEW) å±¥æ­´ã¨ç¾åœ¨ã®çŠ¶æ…‹ã«ä¿å­˜
                            st.session_state.current_prompt = user_prompt
                            st.session_state.current_code = code
                            st.session_state.current_output = output
                            st.session_state.current_explanation = explanation
                            st.session_state.current_interpretation = interpretation
                            
                            # (NEW) å±¥æ­´ãƒªã‚¹ãƒˆã®å…ˆé ­ã«è¿½åŠ 
                            history_entry = {
                                "id": datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                                "prompt": user_prompt,
                                "code": code,
                                "output": output,
                                "explanation": explanation,
                                "interpretation": interpretation
                            }
                            st.session_state.analysis_history.insert(0, history_entry)
                            
                            st.success("åˆ†æãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸã€‚")
                        else:
                            st.error("ã‚³ãƒ¼ãƒ‰ã¯å®Ÿè¡Œã•ã‚Œã¾ã—ãŸãŒã€'output' å¤‰æ•°ã«çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                            
                    except Exception as e:
                        st.error(f"ã‚³ãƒ¼ãƒ‰ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\n{traceback.format_exc()}")
                        st.session_state.current_output = None # å¤±æ•—ã—ãŸã‚‰çµæœã‚’ã‚¯ãƒªã‚¢

        st.markdown("---")
        
        # (NEW) ç¾åœ¨ã®çŠ¶æ…‹ï¼ˆcurrentï¼‰ã‚’è¡¨ç¤ºã™ã‚‹
        display_analysis_results(
            st.session_state.current_prompt,
            st.session_state.current_code,
            st.session_state.current_output,
            st.session_state.current_explanation,
            st.session_state.current_interpretation
        )


    # --- å³ã‚«ãƒ©ãƒ  (col2): ãƒ‡ãƒ¼ã‚¿å‚ç…§ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ã‚¹ã‚­ãƒ¼ãƒã€å±¥æ­´ï¼‰ ---
    with col2:
        st.header("ãƒ‡ãƒ¼ã‚¿å‚ç…§")
        
        st.subheader("ãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­100è¡Œ (ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼)")
        st.dataframe(st.session_state.df.head(100), use_container_width=True, height=300)
        
        with st.expander("æ‹¡å¼µã‚¹ã‚­ãƒ¼ãƒ (AIã«é€ä¿¡ã™ã‚‹æƒ…å ±) ã‚’è¡¨ç¤º"):
            st.write("AIã¯ã“ã®ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã®ã¿ã‚’å‚ç…§ã—ã¾ã™ã€‚")
            st.json(st.session_state.schema_dict, expanded=False)

        st.markdown("---")
        
        # (NEW) åˆ†æå±¥æ­´
        st.header("åˆ†æå±¥æ­´")
        if not st.session_state.analysis_history:
            st.caption("åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ã“ã“ã«å±¥æ­´ãŒä¿å­˜ã•ã‚Œã¾ã™ã€‚")
        
        for i, entry in enumerate(st.session_state.analysis_history):
            # å±¥æ­´é …ç›®ã‚’ãƒœã‚¿ãƒ³ã¨ã—ã¦è¡¨ç¤º
            if st.button(f"ğŸ•’ {entry['id']}\n{entry['prompt'][:50]}..."):
                # (NEW) å±¥æ­´å‘¼ã³å‡ºã—: ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã‚‰ã€ãã®å±¥æ­´ã‚’ã€Œç¾åœ¨ã€ã®çŠ¶æ…‹ã«ã‚³ãƒ”ãƒ¼ã™ã‚‹
                st.session_state.current_prompt = entry["prompt"]
                st.session_state.current_code = entry["code"]
                st.session_state.current_output = entry["output"]
                st.session_state.current_explanation = entry["explanation"]
                st.session_state.current_interpretation = entry["interpretation"]
                # Streamlitã¯è‡ªå‹•ã§å†å®Ÿè¡Œã•ã‚Œã€å·¦ã‚«ãƒ©ãƒ ã®è¡¨ç¤ºãŒæ›´æ–°ã•ã‚Œã‚‹
